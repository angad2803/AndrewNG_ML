# ðŸ“Š Multiple Linear Regression â€” Summary

## ðŸ”¹ Whatâ€™s New This Week?

- You're now learning how to make **linear regression faster and more powerful**.
- You'll explore **multiple features** instead of just one.

---

## ðŸ  From One Feature to Many

- **Original model**:
  - One feature (`x`) â†’ `f_wb(x) = w * x + b`
- **Expanded model**:
  - Multiple features like:
    - `xâ‚`: size of house
    - `xâ‚‚`: number of bedrooms
    - `xâ‚ƒ`: number of floors
    - `xâ‚„`: age of home
  - New model:  
    `f_wb(x) = wâ‚xâ‚ + wâ‚‚xâ‚‚ + wâ‚ƒxâ‚ƒ + wâ‚„xâ‚„ + b`

---

## ðŸ§® Notation

- `n`: number of features (e.g., 4)
- `Xâ½â±â¾`: vector of features for the *i*th training example
- `Xâ½â±â¾â±¼`: *j*th feature of the *i*th example
- `w = [wâ‚, wâ‚‚, ..., wâ‚™]`: weight vector (parameters)
- `x = [xâ‚, xâ‚‚, ..., xâ‚™]`: feature vector
- `b`: bias (intercept)
- Arrows over `x` and `w` â†’ indicate they are vectors

---

## ðŸ”¢ Model Interpretation

Example model:

```
f_wb(x) = 0.1 * xâ‚ + 4 * xâ‚‚ + 10 * xâ‚ƒ - 2 * xâ‚„ + 80
```

Interpreted as:

- Base price = $80,000
- +$100 per sq ft (`0.1 Ã— $1000`)
- +$4000 per bedroom
- +$10,000 per floor
- -$2000 per year of age

---

## âž— Dot Product Notation

- Dot product: `w â‹… x = wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚™xâ‚™`
- Final model:  
  `f_wb(x) = w â‹… x + b`

---

## ðŸ“˜ Terms

| Term                           | Meaning                                       |
| ------------------------------ | --------------------------------------------- |
| **Univariate Regression**      | One feature                                   |
| **Multiple Linear Regression** | Multiple input features                       |
| **Multivariate Regression**    | _Not_ used here; refers to multiple _outputs_ |

---

## âœ… Whatâ€™s Next?

> Youâ€™ll learn about **vectorization**, a trick to make implementation more efficient and elegant.
