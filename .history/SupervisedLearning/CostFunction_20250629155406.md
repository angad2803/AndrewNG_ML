# Cost Function in Linear Regression

## Overview

The cost function measures how well a linear model fits training data. For a model `f(x) = w * x + b`, we minimize `J(w, b)` to find optimal parameters.

## Simplified Model (b = 0)

When we set `b = 0`, the model becomes `f(x) = w * x` with cost function:

```
J(w) = (1/2m) * Σ (w * xᵢ - yᵢ)²
```

## Cost Function Visualization

Using dataset `(1,1), (2,2), (3,3)`:

| w value  | Cost J(w)      | Result        |
| -------- | -------------- | ------------- |
| w = 1    | J(1) = 0       | Perfect fit   |
| w = 0.5  | J(0.5) ≈ 0.58  | Good fit      |
| w = 0    | J(0) ≈ 2.33    | Poor fit      |
| w = -0.5 | J(-0.5) ≈ 5.25 | Very poor fit |

## Key Insights

- **Goal**: Find w that minimizes J(w)
- **Optimal w = 1** for this dataset (produces line y = x)
- **Cost increases** as predictions deviate from actual values
- **Cost function** creates a curve showing how good each w value is

## Next Steps

The full cost function with both w and b parameters will be visualized using 3D plots.
